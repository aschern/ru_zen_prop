{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(list([el.replace(\", \", \",\").replace(\"/ \", \"/\").replace(\" \", \"_\") for el in set(hist.keys()) if \"WT\" not in el])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels_path\n",
    "111111111       Appeal_to_Authority     265     323\n",
    "111111111       Appeal_to_Authority     1795    1935\n",
    "\n",
    "dev-task-TC-template.out то же, но со знаками вопроса\n",
    "\n",
    "article111111111.txt лежат в train_data_folder\n",
    "\n",
    "data_dir - будет закеширован препроцесснутый\n",
    "\n",
    "predicted_logits_files - тут по идее будут предикты (логиты лежать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json(path_or_buf=\"datasets/all.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Comments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>От главы ВОЗ Гебреисуса потребовали прекратить...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 68, (WT) Opinion], [192, 320, Appeal to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Начало. Коронавирус COVID-19 пришелец из космо...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 49, (WT) Opinion], [0, 49, (WTO) Irreleva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Загадка коронавируса, чипирование и новое буду...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 49, (WT) Opinion], [0, 49, (WTO) Obfuscat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>От вакцинации от коронавируса к чипированию //...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 43, (WT) Opinion], [0, 43, (WTO) Irreleva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>Наталья Попова’ (2020) КОРОНАВИРУСА НЕ СУЩЕСТВ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[23, 50, (WTO) Irrelevant data / uncheckable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>22</td>\n",
       "      <td>Зачем Билл Гейтс хочет нас чипировать под пред...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 66, (WT) Opinion], [189, 672, Casting Dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>23</td>\n",
       "      <td>Прикрываясь коронавирусом, в США активно продв...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 78, (WT) Opinion], [0, 78, (WTO) Irreleva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>24</td>\n",
       "      <td>Антиоксиданты против Covid // Яндекс. Дзен. На...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 26, (WT) Opinion], [0, 26, (WTO) Irreleva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>25</td>\n",
       "      <td>Преемник преподобного Паисия старец Евфимий о ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 108, (WT) Other], [273, 734, Appeal to au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>27</td>\n",
       "      <td>Почему вредно носить маску? // Яндекс. Дзен; П...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 26, (WT) Opinion], [0, 26, (WTO) Emotiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text Comments  \\\n",
       "0    26  От главы ВОЗ Гебреисуса потребовали прекратить...       []   \n",
       "1    28  Начало. Коронавирус COVID-19 пришелец из космо...       []   \n",
       "2    29  Загадка коронавируса, чипирование и новое буду...       []   \n",
       "3    30  От вакцинации от коронавируса к чипированию //...       []   \n",
       "4    31  Наталья Попова’ (2020) КОРОНАВИРУСА НЕ СУЩЕСТВ...       []   \n",
       "..   ..                                                ...      ...   \n",
       "120  22  Зачем Билл Гейтс хочет нас чипировать под пред...       []   \n",
       "121  23  Прикрываясь коронавирусом, в США активно продв...       []   \n",
       "122  24  Антиоксиданты против Covid // Яндекс. Дзен. На...       []   \n",
       "123  25  Преемник преподобного Паисия старец Евфимий о ...       []   \n",
       "124  27  Почему вредно носить маску? // Яндекс. Дзен; П...       []   \n",
       "\n",
       "                                                 label  \n",
       "0    [[0, 68, (WT) Opinion], [192, 320, Appeal to a...  \n",
       "1    [[0, 49, (WT) Opinion], [0, 49, (WTO) Irreleva...  \n",
       "2    [[0, 49, (WT) Opinion], [0, 49, (WTO) Obfuscat...  \n",
       "3    [[0, 43, (WT) Opinion], [0, 43, (WTO) Irreleva...  \n",
       "4    [[23, 50, (WTO) Irrelevant data / uncheckable ...  \n",
       "..                                                 ...  \n",
       "120  [[0, 66, (WT) Opinion], [189, 672, Casting Dou...  \n",
       "121  [[0, 78, (WT) Opinion], [0, 78, (WTO) Irreleva...  \n",
       "122  [[0, 26, (WT) Opinion], [0, 26, (WTO) Irreleva...  \n",
       "123  [[0, 108, (WT) Other], [273, 734, Appeal to au...  \n",
       "124  [[0, 26, (WT) Opinion], [0, 26, (WTO) Emotiona...  \n",
       "\n",
       "[125 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_set(data, text_folder, labels_file, save_labels=True):\n",
    "    if os.path.exists(labels_file):\n",
    "        os.remove(labels_file)\n",
    "    for i in range(len(data)):\n",
    "        example = data.iloc[i]\n",
    "        text = example.text\n",
    "        with open(os.path.join(text_folder, \"article\" + str(example.id) + \".txt\"), \"w\") as f:\n",
    "            f.write(text)\n",
    "        with open(labels_file, \"a+\") as f:\n",
    "            for label in example.label:\n",
    "                spl = str(label[0])\n",
    "                spr = str(label[1])\n",
    "                label = label[2].replace(\", \", \",\").replace(\" / \", \"/\").replace(\" \", \"_\")\n",
    "                if \"WT\" not in label:\n",
    "                    if not save_labels:\n",
    "                        label = \"?\"\n",
    "                    f.write(\"\\t\".join([str(example.id), label, spl, spr]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_set(train, \"datasets/train-articles\", \"datasets/train-task2-TC.labels\", save_labels=True)\n",
    "create_set(test, \"datasets/dev-articles\", \"datasets/dev-task-TC-template_labeled.out\", save_labels=True)\n",
    "create_set(test, \"datasets/dev-articles\", \"datasets/dev-task-TC-template.out\", save_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strawman 0.017 0.019\n",
      "Appeal_to_authority 0.101 0.083\n",
      "Simplified_Interpretation 0.03 0.006\n",
      "Loaded_language 0.076 0.109\n",
      "“you_should” 0.021 0.032\n",
      "Hate_speech,slang,name_calling 0.098 0.122\n",
      "Sensational_and/or_provocative_headings 0.024 0.019\n",
      "Causal_Simplification 0.048 0.038\n",
      "False_Dilemma 0.017 0.013\n",
      "Conversation_Killer 0.004 0.0\n",
      "Exaggeration/Minimization 0.026 0.022\n",
      "Casting_Doubt 0.085 0.103\n",
      "Consequential_Simplification 0.009 0.0\n",
      "Appeal_to_Hypocrisy 0.045 0.051\n",
      "Statistical_deception 0.036 0.026\n",
      "Appeal_to_popularity 0.008 0.016\n",
      "Distraction_by_scapegoat 0.027 0.016\n",
      "Appeal_to_fear/prejudice 0.034 0.058\n",
      "Negative/Positive_concepts 0.045 0.026\n",
      "Obfuscation,vagueness,obscurantism 0.013 0.019\n",
      "Labelling 0.081 0.09\n",
      "Appeal_to_Time 0.005 0.013\n",
      "Substitution_of_an_idea 0.028 0.013\n",
      "Guilt_by_Association 0.009 0.003\n",
      "Appeal_to_values 0.029 0.022\n",
      "Stereotypes 0.008 0.019\n",
      "Whataboutism 0.004 0.0\n",
      "Flag_waving 0.017 0.01\n",
      "Rumours 0.022 0.016\n",
      "Repetition 0.012 0.003\n",
      "Red_Herring 0.004 0.006\n",
      "Slogan 0.006 0.01\n",
      "“I_am_like_you” 0.006 0.013\n",
      "(PT)_Call 0.001 0.0\n",
      "Greenwashing 0.003 0.0\n",
      "Bluewashing 0.001 0.003\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_labels = pd.read_csv(\"datasets/train-task2-TC.labels\", sep=\"\\t\", header=None)[1].values\n",
    "dev_labels = pd.read_csv(\"datasets/dev-task-TC-template_labeled.out\", sep=\"\\t\", header=None)[1].values\n",
    "train_labels_c = Counter(train_labels)\n",
    "dev_labels_c = Counter(dev_labels)\n",
    "for el in train_labels_c:\n",
    "    print(el, round(train_labels_c[el] / len(train_labels), 3), round(dev_labels_c.get(el, 0) / len(dev_labels), 3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Дальше в консоль под propaganda env (conda activate propaganda)\n",
    "\n",
    "python -m technique_classification --config configs/tc_config.yml --split_dataset --overwrite_cache\n",
    "CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node 4 technique_classification --config configs/tc_config.yml --do_train --do_eval"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "разметка dev в http://localhost:8872/edit/FEVER2.0/propaganda/semeval2020_task11/datasets/dev-task-TC-template_labeled.out\n",
    "\n",
    "model_name_or_path: model_checkpoints/tc_roberta - обучена с длиной на 0.32, 0.12\n",
    "\n",
    "--do_predict\n",
    "\n",
    "потом\n",
    "\n",
    "--create_submission_file\n",
    "\n",
    "(и может быть нужно --overwrite_cache)\n",
    "\n",
    "propaganda_techniques_file: russian_corpus_techniques.txt\n",
    "train_data_folder: datasets/train-articles\n",
    "test_data_folder: datasets/dev-articles\n",
    "labels_path: datasets/train-task2-TC.labels\n",
    "test_template_labels_path: datasets/dev-task-TC-template_labeled.out\n",
    "test_labels_path: datasets/dev-task-TC-template_labeled.out\n",
    "\n",
    "model_name_or_path: model_checkpoints/tc_roberta\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=1 python -m technique_classification --config configs/tc_config.yml --use_length --overwrite_cache --do_predict --create_submission_file\n",
    "\n",
    "10/06/2023 22:20:46 - INFO - technique_classification.transformers_classifier.run_glue -   ***** Eval results tc_roberta *****\n",
    "10/06/2023 22:20:46 - INFO - technique_classification.transformers_classifier.run_glue -     acc = 0.3782051282051282\n",
    "10/06/2023 22:20:46 - INFO - technique_classification.transformers_classifier.run_glue -     acc_and_f1 = 0.26540479101309217\n",
    "10/06/2023 22:20:46 - INFO - technique_classification.transformers_classifier.run_glue -     f1 = 0.1526044538210561\n",
    "\n",
    "tc_roberta_v2 - то же, но 1 карта на 14 эпох"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://russiansuperglue.com/leaderboard/2\n",
    "\n",
    "https://huggingface.co/ai-forever/ruRoberta-large"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name_or_path: roberta-base\n",
    "#model_name_or_path: model_checkpoints/tc_roberta_base\n",
    "max_seq_length: 256\n",
    "per_gpu_train_batch_size: 16\n",
    "per_gpu_eval_batch_size: 16\n",
    "learning_rate: 2e-5\n",
    "save_steps: 700\n",
    "warmup_steps: 300\n",
    "num_train_epochs: 15\n",
    "output_dir: model_checkpoints/tc_roberta_base\n",
    "do_lower_case: True\n",
    "\n",
    "eval\n",
    "04/27/2023 10:09:06 - INFO - technique_classification.transformers_classifier.run_glue -     acc = 0.0945273631840796\n",
    "04/27/2023 10:09:06 - INFO - technique_classification.transformers_classifier.run_glue -     acc_and_f1 = 0.06699933165375224\n",
    "04/27/2023 10:09:06 - INFO - technique_classification.transformers_classifier.run_glue -     f1 = 0.03947130012342489\n",
    "\n",
    "train\n",
    "04/27/2023 10:23:14 - INFO - technique_classification.transformers_classifier.run_glue -     acc = 0.28747284576393917\n",
    "04/27/2023 10:23:14 - INFO - technique_classification.transformers_classifier.run_glue -     acc_and_f1 = 0.18631402970214078\n",
    "04/27/2023 10:23:14 - INFO - technique_classification.transformers_classifier.run_glue -     f1 = 0.08515521364034241"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name_or_path: pretrained\n",
    "#model_name_or_path: model_checkpoints/tc_roberta_base\n",
    "max_seq_length: 128\n",
    "per_gpu_train_batch_size: 4\n",
    "per_gpu_eval_batch_size: 4\n",
    "learning_rate: 2e-5\n",
    "save_steps: 1700\n",
    "warmup_steps: 700\n",
    "num_train_epochs: 10\n",
    "output_dir: model_checkpoints/tc_roberta_base\n",
    "do_lower_case: True\n",
    "    \n",
    "    \n",
    "04/27/2023 14:23:25 - INFO - technique_classification.transformers_classifier.run_glue -     acc = 0.3383084577114428\n",
    "04/27/2023 14:23:25 - INFO - technique_classification.transformers_classifier.run_glue -     acc_and_f1 = 0.249650315264556\n",
    "04/27/2023 14:23:25 - INFO - technique_classification.transformers_classifier.run_glue -     f1 = 0.1609921728176692\n",
    "\n",
    "train 0.97\n",
    "\n",
    "6 эпох\n",
    "04/27/2023 14:35:43 - INFO - technique_classification.transformers_classifier.run_glue -     acc = 0.34328358208955223\n",
    "04/27/2023 14:35:43 - INFO - technique_classification.transformers_classifier.run_glue -     acc_and_f1 = 0.2614545445149639\n",
    "04/27/2023 14:35:43 - INFO - technique_classification.transformers_classifier.run_glue -     f1 = 0.17962550694037557\n",
    "\n",
    "4 эпохи\n",
    "04/27/2023 16:05:04 - INFO - technique_classification.transformers_classifier.run_glue -     acc = 0.3582089552238806\n",
    "04/27/2023 16:05:04 - INFO - technique_classification.transformers_classifier.run_glue -     acc_and_f1 = 0.2514201592879264\n",
    "04/27/2023 16:05:04 - INFO - technique_classification.transformers_classifier.run_glue -     f1 = 0.14463136335197221\n",
    "\n",
    "\n",
    "4 x 6 лучшее примерно 9 эпох\n",
    "\n",
    "max_seq_length: 128\n",
    "per_gpu_train_batch_size: 4\n",
    "per_gpu_eval_batch_size: 2\n",
    "gradient_accumulation_steps: 6\n",
    "learning_rate: 1e-5\n",
    "save_steps: 200\n",
    "warmup_steps: 300\n",
    "num_train_epochs: 9\n",
    "\n",
    "замегил на 3 x 8 - ничего не учится, странно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justification &  0.509 \\\\\n",
      "Manipulation &  0.34 \\\\\n",
      "Distraction &  0.328 \\\\\n",
      "Attack on Reputation &  0.605 \\\\\n",
      "Simplification &  0.3 \\\\\n",
      "Call &  0.538 \\\\\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "labelsn = ['Negative/Positive_concepts',\n",
    " '(PT)_Call',\n",
    " 'Slogan',\n",
    " 'Obfuscation,vagueness,obscurantism',\n",
    " 'Consequential_Simplification',\n",
    " 'Greenwashing',\n",
    " 'Causal_Simplification',\n",
    " 'Appeal_to_Hypocrisy',\n",
    " 'Appeal_to_values',\n",
    " 'Rumours',\n",
    " 'Strawman',\n",
    " 'Whataboutism',\n",
    " 'Hate_speech,slang,name_calling',\n",
    " 'Casting_Doubt',\n",
    " 'Labelling',\n",
    " 'Substitution_of_an_idea',\n",
    " 'Statistical_deception',\n",
    " 'Bluewashing',\n",
    " 'Appeal_to_authority',\n",
    " 'Guilt_by_Association',\n",
    " 'Appeal_to_Time',\n",
    " 'Flag_waving',\n",
    " '“you_should”',\n",
    " 'Simplified_Interpretation',\n",
    " 'Appeal_to_fear/prejudice',\n",
    " 'Loaded_language',\n",
    " 'Sensational_and/or_provocative_headings',\n",
    " '“I_am_like_you”',\n",
    " 'Exaggeration/Minimization',\n",
    " 'Red_Herring',\n",
    " 'Appeal_to_popularity',\n",
    " 'Repetition',\n",
    " 'False_Dilemma',\n",
    " 'Distraction_by_scapegoat',\n",
    " 'Conversation_Killer',\n",
    " 'Stereotypes']\n",
    "\n",
    "justif = \"\"\"\n",
    "\\item Appeal to authority (including references to an authority that is irrelevant to the topic being commented on, an expert without a confirmed current status),\n",
    "\\item Appeal to popularity,\n",
    "\\item Appeal to values, including references to virtue,\n",
    "\\item Appeal to fear / prejudice,\n",
    "\\item Greenwashing: justification through appeal to green politics,\n",
    "\\item Bluewashing: justification through participation in international humanitarian initiatives (often as UN projects, but not only),\n",
    "\\item Flag waving (appeal to national interests to justify ideas),\n",
    "Rumours\n",
    "\"\"\"\n",
    "\n",
    "simple = \"\"\"\n",
    "\\item Causal Simplification,\n",
    "\\item False Dilemma or no Choice,\n",
    "\\item Consequential Simplification,\n",
    "\\item Simplified Interpretation,\n",
    "\\item Stereotypes (an attempt to evoke negativity towards an alternative scenario, often based on prejudice),\n",
    "\\item ``I am like you'' or ``like everyone else'' (an attempt to convince the target audience to join in and take a course of action because ``everyone else is doing the same thing''): this is what all or ``positive'' nations / parties / groups do,\n",
    "\"\"\"\n",
    "\n",
    "distraction = \"\"\"\n",
    "\\item Strawman,\n",
    "\\item Red Herring,\n",
    "\\item Whataboutism,\n",
    "\\item Appeal to Hypocrisy (‘Tu quoque’),\n",
    "\\item Distraction by scapegoat (a combination of ``strawman'' and adhominem - to assign someone to blame in order to remove criticism from another person),\n",
    "\\item Substitution of an idea / topic / issue,\n",
    "\"\"\"\n",
    "\n",
    "call = \"\"\"\n",
    "\\item Slogan,\n",
    "\\item Conversation Killer,\n",
    "\\item Appeal to Time,\n",
    "\\item ``you should'', ``never do...'', ``you must...'',\n",
    "(PT) Call\n",
    "\"\"\"\n",
    "\n",
    "manip = \"\"\"\n",
    "\\item Loaded language,\n",
    "\\item Sensational and/or provocative headings, \n",
    "\\item Repetition,\n",
    "\\item Exaggeration / Minimization, \n",
    "\\item Obfuscation, vagueness, obscurantism,\n",
    "\\item Statistical deception (shift of e\n",
    "\"\"\"\n",
    "\n",
    "attack = \"\"\"\n",
    "\\item Labelling,\n",
    "\\item Hate speech, slang, name calling: demonization, offensive epithets, metaphors, names related to a particular phenomenon / organization / country / nation / person / idea, etc., are used to discredit something / someone,\n",
    "\\item such negative concepts as ``authoritarianism'', ``aggression'', ``enemy'', ``imperialism'', ``terrorism'', ``militarism'', ``nationalism'', ``occupation'', ``racism'', ``totalitarianism'', ``junta'' are exploited. And, on the contrary, such positive concepts as ``brotherhood'', ``democracy'', ``friendship'', ``health'', ``quality'', ``love'', ``peace'', ``patriotism'', ``victory'', ``superiority'', ``prosperity'', ``equality'', ``freedom'', ``commonwealth'', ``happiness'', ``success'', etc.,\n",
    "\\item Casting Doubt,\n",
    "\\item Guilt by Association (Reductio ad Hitlerum).\n",
    "\"\"\"\n",
    "\n",
    "metalabels = {}\n",
    "for label in labelsn:\n",
    "    cur = label[1:-1].replace(\"_\", \" \").split(\"/\")[0].split(\",\")[0]\n",
    "    if cur in justif:\n",
    "        metalabels[label] = \"Justification\"\n",
    "    elif cur in simple:\n",
    "        metalabels[label] = \"Simplification\"\n",
    "    elif cur in distraction:\n",
    "        metalabels[label] = \"Distraction\"\n",
    "    elif cur in call:\n",
    "        metalabels[label] = \"Call\"\n",
    "    elif cur in manip:\n",
    "        metalabels[label] = \"Manipulation\"\n",
    "    elif cur in attack:\n",
    "        metalabels[label] = \"Attack on Reputation\"\n",
    "    else:\n",
    "        print(label)\n",
    "    \n",
    "\n",
    "def replace_metalabels(preds):\n",
    "    res = []\n",
    "    for label in preds:\n",
    "        res.append(metalabels[label])\n",
    "    return np.array(res)\n",
    "\n",
    "labels = pd.read_csv(\"datasets/dev-task-TC-template_labeled_meta.out\", sep=\"\\t\", header=None)[1].values\n",
    "preds = pd.read_csv(\"results/TC_output_dev_meta.txt\", sep=\"\\t\", header=None)[1].values\n",
    "\n",
    "#labels = replace_metalabels(labels)\n",
    "#preds = replace_metalabels(preds)\n",
    "\n",
    "scores = []\n",
    "names = list(set(metalabels.values())) #labelsn\n",
    "for label in names: #labelsn:\n",
    "    dlabels = copy.deepcopy(labels)\n",
    "    dpreds = copy.deepcopy(preds)\n",
    "    dlabels[labels == label] = \"1\"\n",
    "    dlabels[dlabels != \"1\"] = \"0\"\n",
    "    dpreds[preds == label] = \"1\"\n",
    "    dpreds[dpreds != \"1\"] = \"0\"\n",
    "    dlabels = np.array(dlabels, dtype=int)\n",
    "    dpreds = np.array(dpreds, dtype=int)\n",
    "    scores.append(f1_score(dlabels, dpreds))\n",
    "\n",
    "for name, score in zip(names, scores):\n",
    "    if score != 0:\n",
    "        print( name.replace(\"_\", \" \") + \" & \", round(score, 3), r\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.483974358974359, 0.43687910686366677)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "labels = pd.read_csv(\"datasets/dev-task-TC-template_labeled_meta.out\", sep=\"\\t\", header=None)[1].values\n",
    "preds = pd.read_csv(\"results/TC_output_dev_meta.txt\", sep=\"\\t\", header=None)[1].values\n",
    "accuracy_score(labels, preds), f1_score(labels, preds, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Attack on Reputation', 'Attack on Reputation', 'Justification',\n",
       "       'Manipulation', 'Manipulation', 'Manipulation',\n",
       "       'Attack on Reputation', 'Justification', 'Simplification',\n",
       "       'Distraction', 'Simplification', 'Distraction', 'Simplification',\n",
       "       'Distraction', 'Simplification', 'Manipulation', 'Justification',\n",
       "       'Call', 'Simplification', 'Attack on Reputation', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Justification', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Simplification', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Distraction',\n",
       "       'Distraction', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Distraction',\n",
       "       'Justification', 'Justification', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Justification',\n",
       "       'Justification', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Justification', 'Call', 'Justification', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Distraction',\n",
       "       'Distraction', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Distraction', 'Attack on Reputation',\n",
       "       'Distraction', 'Distraction', 'Attack on Reputation',\n",
       "       'Simplification', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Simplification', 'Manipulation',\n",
       "       'Manipulation', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Justification', 'Manipulation',\n",
       "       'Simplification', 'Attack on Reputation', 'Manipulation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Simplification',\n",
       "       'Attack on Reputation', 'Justification', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Manipulation',\n",
       "       'Manipulation', 'Distraction', 'Attack on Reputation',\n",
       "       'Justification', 'Distraction', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Call', 'Attack on Reputation',\n",
       "       'Justification', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Simplification', 'Simplification', 'Manipulation', 'Manipulation',\n",
       "       'Simplification', 'Simplification', 'Simplification',\n",
       "       'Manipulation', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Simplification', 'Attack on Reputation',\n",
       "       'Justification', 'Distraction', 'Attack on Reputation', 'Call',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Distraction',\n",
       "       'Justification', 'Justification', 'Attack on Reputation',\n",
       "       'Justification', 'Attack on Reputation', 'Justification', 'Call',\n",
       "       'Justification', 'Justification', 'Call', 'Attack on Reputation',\n",
       "       'Distraction', 'Attack on Reputation', 'Call',\n",
       "       'Attack on Reputation', 'Manipulation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Manipulation', 'Manipulation',\n",
       "       'Manipulation', 'Manipulation', 'Justification',\n",
       "       'Attack on Reputation', 'Justification', 'Call',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Justification', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Simplification',\n",
       "       'Manipulation', 'Attack on Reputation', 'Simplification',\n",
       "       'Distraction', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Manipulation', 'Attack on Reputation', 'Distraction',\n",
       "       'Attack on Reputation', 'Distraction', 'Attack on Reputation',\n",
       "       'Manipulation', 'Manipulation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Distraction', 'Justification',\n",
       "       'Manipulation', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Justification', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Manipulation',\n",
       "       'Justification', 'Attack on Reputation', 'Justification',\n",
       "       'Justification', 'Attack on Reputation', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Simplification',\n",
       "       'Simplification', 'Attack on Reputation', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Justification',\n",
       "       'Manipulation', 'Manipulation', 'Attack on Reputation',\n",
       "       'Simplification', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Manipulation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Manipulation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Manipulation', 'Justification',\n",
       "       'Attack on Reputation', 'Distraction', 'Distraction',\n",
       "       'Manipulation', 'Manipulation', 'Manipulation', 'Distraction',\n",
       "       'Attack on Reputation', 'Simplification', 'Justification',\n",
       "       'Justification', 'Simplification', 'Simplification', 'Call',\n",
       "       'Manipulation', 'Manipulation', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Simplification',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Distraction',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Manipulation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Justification',\n",
       "       'Justification', 'Justification', 'Attack on Reputation',\n",
       "       'Justification', 'Manipulation', 'Manipulation', 'Justification',\n",
       "       'Attack on Reputation', 'Attack on Reputation', 'Manipulation',\n",
       "       'Attack on Reputation', 'Simplification', 'Distraction',\n",
       "       'Justification', 'Attack on Reputation', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Justification', 'Justification',\n",
       "       'Justification', 'Simplification', 'Attack on Reputation',\n",
       "       'Attack on Reputation', 'Distraction', 'Attack on Reputation',\n",
       "       'Distraction', 'Simplification', 'Justification', 'Simplification',\n",
       "       'Simplification', 'Simplification', 'Justification',\n",
       "       'Justification', 'Simplification'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/dev-task-TC-template_labeled.out\",sep=\"\\t\", header=None)\n",
    "df[1] = replace_metalabels(df[1].values)\n",
    "df.to_csv(\"datasets/dev-task-TC-template_labeled_meta.out\", header=None,sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_set_si(data, labels_file):\n",
    "    if os.path.exists(labels_file):\n",
    "        os.remove(labels_file)\n",
    "    for i in range(len(data)):\n",
    "        example = data.iloc[i]\n",
    "        text = example.text\n",
    "        with open(labels_file, \"a+\") as f:\n",
    "            for label in example.label:\n",
    "                spl = str(label[0])\n",
    "                spr = str(label[1])\n",
    "                label = label[2].replace(\", \", \",\").replace(\" / \", \"/\").replace(\" \", \"_\")\n",
    "                if \"WT\" not in label:\n",
    "                    f.write(\"\\t\".join([str(example.id), spl, spr]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_set_si(train, \"datasets/train-task1-SI.labels\")\n",
    "create_set_si(test, \"results/dev-task-SI.labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({46, 51, 62, 122}, set())"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labels = pd.read_csv(\"results/dev-task-SI.labels\", sep=\"\\t\", header=None)\n",
    "preds = pd.read_csv(\"results/SI_output_dev.txt\", sep=\"\\t\", header=None)\n",
    "set(labels[0].values) - set(preds[0].values), set(preds[0].values) - set(labels[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"attention_probs_dropout_prob\": 0.1,\\n  \"bos_token_id\": 0,\\n  \"eos_token_id\": 2,\\n  \"gradient_checkpointing\": false,\\n  \"hidden_act\": \"gelu\",\\n  \"hidden_dropout_prob\": 0.1,\\n  \"hidden_size\": 768,\\n  \"initializer_range\": 0.02,\\n  \"intermediate_size\": 3072,\\n  \"layer_norm_eps\": 1e-12,\\n  \"max_position_embeddings\": 512,\\n  \"model_type\": \"roberta\",\\n  \"num_attention_heads\": 12,\\n  \"num_hidden_layers\": 12,\\n  \"pad_token_id\": 1,\\n  \"position_embedding_type\": \"absolute\",\\n  \"transformers_version\": \"4.3.3\",\\n  \"type_vocab_size\": 2,\\n  \"use_cache\": true,\\n  \"vocab_size\": 30522\\n}\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RobertaConfig().to_json_string()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "инитил не с pretrained\n",
    "max_seq_length: 128\n",
    "per_gpu_train_batch_size: 4\n",
    "per_gpu_eval_batch_size: 1\n",
    "learning_rate: 1e-5\n",
    "save_steps: 3000\n",
    "warmup_steps: 500\n",
    "num_train_epochs: 25\n",
    "\n",
    "2023-04-29 19:42:07,224 - INFO - Precision=60.926987/145=0.420186       Recall=64.930583/277=0.234406\n",
    "2023-04-29 19:42:07,224 - INFO - F1=0.300933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "preds = pd.read_csv(\"results/SI_output_dev.txt\", sep=\"\\t\", header=None)\n",
    "preds[3] = [\"?\"] * len(preds)\n",
    "preds = preds[[0, 3, 1, 2]]\n",
    "preds.to_csv(\"results/SI_output_dev_TC_input.txt\", index=False, sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Negative/Positive_concepts',\n",
       " '(PT)_Call',\n",
       " 'Slogan',\n",
       " 'Obfuscation,vagueness,obscurantism',\n",
       " 'Consequential_Simplification',\n",
       " 'Greenwashing',\n",
       " 'Causal_Simplification',\n",
       " 'Appeal_to_Hypocrisy',\n",
       " 'Appeal_to_values',\n",
       " 'Rumours',\n",
       " 'Strawman',\n",
       " 'Whataboutism',\n",
       " 'Hate_speech,slang,name_calling',\n",
       " 'Casting_Doubt',\n",
       " 'Labelling',\n",
       " 'Substitution_of_an_idea',\n",
       " 'Statistical_deception',\n",
       " 'Bluewashing',\n",
       " 'Appeal_to_authority',\n",
       " 'Guilt_by_Association',\n",
       " 'Appeal_to_Time',\n",
       " 'Flag_waving',\n",
       " '“you_should”',\n",
       " 'Simplified_Interpretation',\n",
       " 'Appeal_to_fear/prejudice',\n",
       " 'Loaded_language',\n",
       " 'Sensational_and/or_provocative_headings',\n",
       " '“I_am_like_you”',\n",
       " 'Exaggeration/Minimization',\n",
       " 'Red_Herring',\n",
       " 'Appeal_to_popularity',\n",
       " 'Repetition',\n",
       " 'False_Dilemma',\n",
       " 'Distraction_by_scapegoat',\n",
       " 'Conversation_Killer',\n",
       " 'Stereotypes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Negative/Positive_concepts\n",
    "(PT)_Call\n",
    "Slogan\n",
    "Obfuscation,vagueness,obscurantism\n",
    "Consequential_Simplification\n",
    "Greenwashing\n",
    "Causal_Simplification\n",
    "Appeal_to_Hypocrisy\n",
    "Appeal_to_values\n",
    "Rumours\n",
    "Strawman\n",
    "Whataboutism\n",
    "Hate_speech,slang,name_calling\n",
    "Casting_Doubt\n",
    "Labelling\n",
    "Substitution_of_an_idea\n",
    "Statistical_deception\n",
    "Bluewashing\n",
    "Appeal_to_authority\n",
    "Guilt_by_Association\n",
    "Appeal_to_Time\n",
    "Flag_waving\n",
    "“you_should”\n",
    "Simplified_Interpretation\n",
    "Appeal_to_fear/prejudice\n",
    "Loaded_language\n",
    "Sensational_and/or_provocative_headings\n",
    "“I_am_like_you”\n",
    "Exaggeration/Minimization\n",
    "Red_Herring\n",
    "Appeal_to_popularity\n",
    "Repetition\n",
    "False_Dilemma\n",
    "Distraction_by_scapegoat\n",
    "Conversation_Killer\n",
    "Stereotypes\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20853, 20841]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5c40d40828c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cached_datasets/SI/test_labeled.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mgold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PROP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20853, 20841]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_labels(preds):\n",
    "    labels = []\n",
    "    for el in preds:\n",
    "        if len(el.split(\"\\t\")) > 1:\n",
    "            labels.append(el.split(\"\\t\")[1].strip()[-4:])\n",
    "            if el.startswith(\"см.\\t\"):\n",
    "                labels.append(\"O\")\n",
    "    return labels\n",
    "\n",
    "with open(\"model_checkpoints/si_roberta/test_predictions.txt\", \"r\") as f:\n",
    "    preds = f.readlines()\n",
    "with open(\"cached_datasets/SI/test_labeled.tsv\", \"r\") as f:\n",
    "    gold = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3167\n",
      "3168\n",
      "3350\n",
      "5977\n",
      "8554\n",
      "8566\n",
      "8567\n",
      "9268\n",
      "11032\n",
      "11033\n",
      "12458\n",
      "12459\n",
      "12485\n",
      "12486\n",
      "14142\n",
      "14143\n",
      "21328\n",
      "21330\n",
      "21331\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(preds)):\n",
    "    if gold[i][:2] != preds[i][:2]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1102"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\" \".join(preds).split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.insert(21328, ':\\tO\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36365059486537255"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(get_labels(gold), get_labels(preds), pos_label=\"PROP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42659974905897113"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_preds = []\n",
    "for el in \" \".join(preds).split(\".\"):\n",
    "    if \"PROP\" in el:\n",
    "        sent_preds.append(\"PROP\")\n",
    "    else:\n",
    "        sent_preds.append(\"O\")\n",
    "sent_gold = []\n",
    "for el in \" \".join(gold).split(\".\"):\n",
    "    if \"PROP\" in el:\n",
    "        sent_gold.append(\"PROP\")\n",
    "    else:\n",
    "        sent_gold.append(\"O\")\n",
    "f1_score(sent_gold, sent_preds, pos_label=\"PROP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from span_identification.dataset import *\n",
    "\n",
    "\n",
    "def get_train_dev_files(articles_id, articles_content, nlp, labels_path, train_file, dev_file, split_by_ids=True, \n",
    "                     dev_size=0.3, random_state=42):\n",
    "    articles_content_dict = dict(zip(articles_id, articles_content))\n",
    "    articles_id, gold_spans = read_predictions_from_file(labels_path)\n",
    "    span_list = list(zip(articles_id, gold_spans))\n",
    "    train_data = sorted(group_spans_by_article_ids(span_list).items())\n",
    "    train_ids = [example[0] for example in train_data]\n",
    "    \n",
    "    create_BIO_labeled(train_file, train_data, articles_content_dict, nlp)\n",
    "    \n",
    "    return train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_content_v2 = []\n",
    "for el in articles_content:\n",
    "    articles_content_v2.append(el.replace(\"см.\", \"см .\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00,  9.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['103',\n",
       " '110',\n",
       " '111',\n",
       " '115',\n",
       " '12',\n",
       " '122',\n",
       " '123',\n",
       " '128',\n",
       " '13',\n",
       " '135',\n",
       " '14',\n",
       " '19',\n",
       " '26',\n",
       " '34',\n",
       " '35',\n",
       " '44',\n",
       " '46',\n",
       " '47',\n",
       " '51',\n",
       " '62',\n",
       " '66',\n",
       " '68',\n",
       " '88',\n",
       " '94',\n",
       " '99']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_content, articles_id, propaganda_techniques_names = load_data(\"datasets/dev-articles\", \n",
    "                                                                   \"tools/data/russian_corpus_techniques.txt\")\n",
    "train_file_path = os.path.join(\"cached_datasets/SI/\", \"test_labeled.tsv\")\n",
    "get_train_dev_files(articles_id, articles_content_v2, nlp, \"results/dev-task-SI.labels\", train_file_path,\n",
    "                                         \"\", True, 0.18, 57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propaganda",
   "language": "python",
   "name": "propaganda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
